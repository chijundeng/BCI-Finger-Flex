{
 "cells": [
  {
   "cell_type": "code",
   "id": "f0b443c5-4d11-4d28-bacb-436db2a2c88d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T04:48:26.707901Z",
     "start_time": "2024-11-30T04:48:24.093204Z"
    }
   },
   "source": [
    "'''\n",
    "\n",
    "Finger flexion prediction using transformer encoder\n",
    "@author: Deng Chijun\n",
    "@create date: 2024.11.24\n",
    "@update date: 2024.11.27\n",
    "\n",
    "'''\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import pickle\n",
    "\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "torch.manual_seed(42) \n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "131c2f29-74d7-4cee-81cc-331bf8c3ddb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T04:53:14.599692Z",
     "start_time": "2024-11-30T04:53:14.593447Z"
    }
   },
   "source": [
    "'''\n",
    "Transformer Encoder\n",
    "'''\n",
    "class TransformerRegressor(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, output_dim, pos_dim, dropout=0.1):\n",
    "        super(TransformerRegressor, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, pos_dim, embed_dim))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, \n",
    "                                                   dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(embed_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Reshape input for embedding\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, freq, channels)\n",
    "        x = self.embedding(x) + self.positional_encoding \n",
    "        \n",
    "        x = x.permute(1, 0, 2)  # (freq, batch_size, embed_dim)\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        x = x.mean(dim=0)  # Aggregate over the frequency dimension\n",
    "        x = self.fc(x) \n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "5f728692-ee1c-4239-b031-5aaa088376a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T04:54:14.598560Z",
     "start_time": "2024-11-30T04:53:42.501070Z"
    }
   },
   "source": [
    "'''\n",
    "Train and test for each subject and finger\n",
    "'''\n",
    "# Preprocessed data directory (feature)\n",
    "root_dir = 'E:/Code/Class_Project/BCI_Prj_New/dataset'\n",
    "process_dir = f\"{root_dir}/BCI_Competion4_dataset4_data_fingerflexions/preprocessing\"\n",
    "\n",
    "# Results directory\n",
    "pred_dir = f\"{root_dir}/BCI-Finger-Flex/prediction/transformer\"\n",
    "model_dir = f\"{root_dir}/BCI-Finger-Flex/model/transformer\"\n",
    "\n",
    "# Gaussian filter sigma\n",
    "sigma = 6\n",
    "\n",
    "# Subjects and fingers\n",
    "subs = [3, 2, 1]\n",
    "fingers = ['thumb', 'index', 'middle', 'ring', 'little']\n",
    "\n",
    "for idx, subid in enumerate(subs):\n",
    "    '''\n",
    "    Data loading\n",
    "    '''\n",
    "    data_process_dir = f'{process_dir}/sub{subid}'\n",
    "    \n",
    "    # train\n",
    "    X_train = np.load(f'{data_process_dir}/train/ecog_data.npy')\n",
    "    y_train_all = np.load(f'{data_process_dir}/train/fingerflex_data.npy')\n",
    "    \n",
    "    # test\n",
    "    X_test = np.load(f'{data_process_dir}/val/ecog_data.npy')\n",
    "    y_test_all = np.load(f'{data_process_dir}/val/fingerflex_data.npy')\n",
    "    \n",
    "    # Transpose to (times, channels, wavelets)\n",
    "    X_train = X_train.transpose(2, 0, 1)\n",
    "    X_test = X_test.transpose(2, 0, 1)\n",
    "    y_train_all = y_train_all.transpose(1, 0)\n",
    "    y_test_all = y_test_all.transpose(1, 0)\n",
    "    \n",
    "    # Feature dim\n",
    "    num_wave = X_train.shape[2]\n",
    "    num_node = X_train.shape[1]\n",
    "    \n",
    "    '''\n",
    "    Model Setup\n",
    "    '''\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = TransformerRegressor(input_dim=num_node, embed_dim=256, num_heads=8,\n",
    "                                 num_layers=2, output_dim=1,\n",
    "                                 pos_dim=num_wave).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    \n",
    "    '''\n",
    "    Save dir\n",
    "    '''\n",
    "    # Model save dir\n",
    "    model_finger_dir = f\"{model_dir}/sub{subid}\"\n",
    "    if not os.path.exists(model_finger_dir):\n",
    "        os.makedirs(model_finger_dir)\n",
    "        logging.info(f\"Directory '{model_finger_dir}' created.\")\n",
    "\n",
    "    # Prediction save dir\n",
    "    pred_finger_dir = f\"{pred_dir}/sub{subid}\"\n",
    "    if not os.path.exists(pred_finger_dir):\n",
    "        os.makedirs(pred_finger_dir)\n",
    "        logging.info(f\"Directory '{pred_finger_dir}' created.\")\n",
    "            \n",
    "    for finger_id, finger_name in enumerate(fingers):\n",
    "        # logging train and validation process\n",
    "        logging.info(f\"Subject {subid} {finger_name} flexion prediction using transformer encoder\")\n",
    "        '''\n",
    "        Torch dataloader\n",
    "        '''\n",
    "        y_train = y_train_all[:, finger_id].reshape([-1, 1])\n",
    "        y_test = y_test_all[:, finger_id].reshape([-1, 1])\n",
    "        \n",
    "        # Convert data to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        \n",
    "        batch_size = 128\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Train epoch\n",
    "        epochs = 10\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(X_batch)\n",
    "                loss = criterion(predictions, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # Save model\n",
    "        torch.save(model.state_dict(), f\"{model_finger_dir}/{finger_name}.pth\")\n",
    "\n",
    "        '''\n",
    "        Evaluation and Inference\n",
    "        '''\n",
    "        y_pred = []\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                predictions = model(X_batch)\n",
    "                loss = criterion(predictions, y_batch)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                y_pred.append(predictions.cpu().numpy())\n",
    "                \n",
    "        y_pred = np.concatenate(y_pred, axis=0)  # Combine batch predictions\n",
    "        \n",
    "        print(f\"Test Loss: {test_loss / len(test_loader):.4f}\")\n",
    "        \n",
    "        '''\n",
    "        Calculating Pearson correlation, MSE metrics\n",
    "        '''\n",
    "        y_pred_filter = gaussian_filter1d(y_pred.ravel(), sigma=sigma)\n",
    "        rho, pval = pearsonr(y_test.ravel(), y_pred_filter)\n",
    "        mse = mean_squared_error(y_test.ravel(), y_pred_filter)\n",
    "\n",
    "        # Save prediction and metrics\n",
    "        pred_res = {\n",
    "            'y_test': y_test.ravel(),\n",
    "            'y_pred': y_pred.ravel(),\n",
    "            'y_pred_filter': y_pred_filter.ravel(),\n",
    "            'rho': rho,\n",
    "            'pval': pval,\n",
    "            'mse': mse\n",
    "        }\n",
    "        with open(f\"{pred_finger_dir}/{finger_name}.pkl\", 'wb') as pickle_file:\n",
    "            pickle.dump(pred_res, pickle_file)\n",
    "        \n",
    "        '''\n",
    "        Visualization\n",
    "        '''\n",
    "        sns.set_theme(style='darkgrid', font_scale=1.2)\n",
    "        colors = sns.color_palette(\"Set2\", 2) \n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        # Plot original y\n",
    "        plt.plot(y_test.ravel(), label=\"Ground truth\", alpha=0.7, color=colors[0])\n",
    "        # Plot predicted y\n",
    "        plt.plot(y_pred_filter.ravel(), label=\"Prediction\", alpha=0.7, color=colors[1])\n",
    "        \n",
    "        # Adding labels and legend\n",
    "        plt.title(f\"Prediction of {finger_name} flexion of subject {subid} using transformer encoder (rho = {rho:.3f}, MSE = {mse:.3f})\", fontsize=16)\n",
    "        plt.xlabel(\"Time\", fontsize=16)\n",
    "        plt.ylabel(\"Signal\", fontsize=16)\n",
    "        plt.legend(fontsize=14, loc='upper right')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save figure\n",
    "        plt.savefig(f\"{pred_finger_dir}/{finger_name}.png\", bbox_inches='tight', dpi=300)\n",
    "        plt.show()"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 26\u001B[0m\n\u001B[0;32m     23\u001B[0m data_process_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprocess_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/sub\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msubid\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# train\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m X_train \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mdata_process_dir\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/train/ecog_data.npy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m y_train_all \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata_process_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/train/fingerflex_data.npy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# test\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\EEG_Speech_Detect_T\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:488\u001B[0m, in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[0;32m    485\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m.\u001B[39mopen_memmap(file, mode\u001B[38;5;241m=\u001B[39mmmap_mode,\n\u001B[0;32m    486\u001B[0m                                   max_header_size\u001B[38;5;241m=\u001B[39mmax_header_size)\n\u001B[0;32m    487\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 488\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_pickle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_pickle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mpickle_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpickle_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mmax_header_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_header_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    492\u001B[0m     \u001B[38;5;66;03m# Try a pickle\u001B[39;00m\n\u001B[0;32m    493\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_pickle:\n",
      "File \u001B[1;32m~\\.conda\\envs\\EEG_Speech_Detect_T\\Lib\\site-packages\\numpy\\lib\\format.py:836\u001B[0m, in \u001B[0;36mread_array\u001B[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001B[0m\n\u001B[0;32m    833\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    834\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m isfileobj(fp):\n\u001B[0;32m    835\u001B[0m         \u001B[38;5;66;03m# We can use the fast fromfile() function.\u001B[39;00m\n\u001B[1;32m--> 836\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfromfile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcount\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcount\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    837\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    838\u001B[0m         \u001B[38;5;66;03m# This is not a real file. We have to read it the\u001B[39;00m\n\u001B[0;32m    839\u001B[0m         \u001B[38;5;66;03m# memory-intensive way.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    847\u001B[0m         \u001B[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001B[39;00m\n\u001B[0;32m    848\u001B[0m         \u001B[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001B[39;00m\n\u001B[0;32m    849\u001B[0m         array \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39mndarray(count, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
